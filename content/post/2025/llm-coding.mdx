---
id: 2025/llm-coding
tags: ["tech", "LLM"]
date: 2025-12-11
description: Claudeを使い始めた。雑感とか
title: LLMコーディング始めました
publish: true
---


去年の夏はChat GPTに論文リストを作らせても、10本出してきたらそのうち6本はタイトルも著者も全部「生成」されている有様だった。
単純な質問ならまだ使えるかな、という感じ。それが今年になってからはDeep Researchなしでも嘘が出てくることがほとんどなくなった。
以降調べ物は大体ChatGPT任せや、ChatGPTに大枠を聞いてから調べることが多くなった。

コーディングについては、今年の春とかにGitHub copilot chatを使ってみたときはLLMは使い物にならないなという感覚だった。
Claudeはフロントエンドはまだいけるが、Rustコードは正直厳しいぐらい。
Lifetimeを理解せず、人間なら一瞬でわかるような構文エラーですら詰まる感じだった。
研究室の後輩がClaude MAXを契約したと聞いて、正直自分はそこまで使い物になるとは思っていなかったが勢いで自分もMaxを契約して使い始めた。

前のClaude Sonnet4.5は確かに便利だから使える局面は限られており、APIなので利用料も高額だなと感じていたが、
Claude MAXは定額なのでガンガン使える。値段を考えるとあんまり使えないという問題が無くなった。
何よりRustコードをかなり正しく理解する。ちょっと複雑な設計に起因する型エラーであっても理解する。
前は既存のコードの編集は下手だった印象があるが、今はむしろInputが高速なので人間がコアのロジックやsampleを書いて残りをLLMに書かせるアプローチがむしろ良いのでないかというぐらいだ。生産性が何倍も変わると騒がれていたのも然もありなんと思えた。

ただ完璧ということではなく、バグが発生した場合散漫にパラメータを変えて条件を探ろうとするし、ログをファイルに保存して分析とかも指示しておかないとやってくれない（でも指示すればログ分析をしてくれる。特にログが長い場合人間が追うのは大変なので、ログ分析してデバッグまでやってくれるのは本当に便利）。
あとあまり効率的なコードは書かない。基本的に平均的なそれなりに良い品質のコードという感じ。そしてとにかく小手先の解決を好む傾向がある。
テストでバッファサイズをあげて問題が発生しなくなったから解決とか普通にやってくるので少し閉口する。
コーディング速度は完全に人間越えだが、エンジニアリングと見ると人間には劣る部分も多い、という感じ。

とはいえ総合的には少なくとも自分でコーディングするより圧倒的に速い。料理をしている間Claudeを走らせて作業を進めるとかも普通に出来る。
もう今となってはベンチマークコードを自分でデバッグしながら書くとかやれないかもしれない……。
実際最近は簡単な修正以外はほとんどLLMに任せ、自分でコードを編集していない。人間とLLMの比率については、驚き期間が過ぎればもう少し自分で書く量は増えるかもしれない。

---

ClaudeはCLIではなく[Zed editor](https://zed.dev/)から使っている。これは自分でコードを見たり編集するのが便利だからというのもあるし、
Zedは内部にClaudeのSDKを持っておりUIもZedと馴染むように表示される。これ無料で大丈夫なんだろうか。
Zedだとremote sshを使うとClaudeは手元で動き、コード実行はサーバ側で行われる（多分Zedが勝手にsshで繋いでいるんだと思う）。
そのためClaudeはこの環境の違いをイマイチ理解しておらず、planファイルの書き込みに失敗したりしている（コマンドはSSH先、編集もSSH先、ただしClaude自体はローカルなのでClaudeの機能でPlanファイルを書くのに失敗する？みたい）。
それにZed公式が提供するClaudeでないとコンテキストの保存もできない。ドキュメントを都度書かせておけばあまり困らないし、プロジェクトの理解力も高いので案外大丈夫だがやや不便ではある。
[一応改善されそうな気配はある](https://zed.dev/blog/claude-code-via-acp?utm_source=chatgpt.com)が、
ZedはACPで共通化された実装でやる方向性なのですぐに直るわけではないかもしれない。

---

今までLLMでエンジニアの職業が消えるとかの話をやや冷ややかに見ていた部分があるが、
本格的に使い始めて確かにこれは世界が変わるなと思った。アセンブリからC言語への移行以上のインパクトがあるかもしれない（その時代を経験してはいないが）。
AIに理解しやすいコーディングというのは正直わからない（LLMにとって優れたコードは人間にとっても優れたコードになると思う）。
ただ、LLM向けの半構造化テキストフォーマットのようなものは一考の余地があると思えた。
少なくともコーディングプロセスは大きく変わるだろう。補助というよりLLMを人間がコントロールする形が最速だし結果的には精度も良いだろう（実際、
私が書くのと違って単純なtypoによるバグや設計では考慮していたものを実装し忘れるみたいなショボいバグは極端に少ない）。
レビューに関してもLLMにサマリやコアのロジックを先に判別させることも検討して良いと思う。

---

自分はLLMが存在しない状態でプログラミングをしていた最後の世代に近い。これからの世代のソフトウェアエンジニアはおそらくLLMによるコーディングが当然の時代になる。圧倒的に実装速度が上がるだけではなく、こうしたコーディングに慣れているのでもはや私は太刀打ちできないかもしれない。一方で、自分で書く機会が減ることが悪い影響を与えるのかもしれない。いい方向に進んで欲しいと思う。最大の懸念はLLMの利用料はそれなりに高額であること。[Cerebras](https://www.cerebras.ai/)、[Tenstorrent](https://tenstorrent.com/ja)、国内では[Preferred Networks](https://www.preferred.jp/ja/news/pr20241115)といった会社が
アクセラレータを開発しているが、劇的にコストが下がることはないだろう。経済力の差が能力の差につながってほしくはない……。
